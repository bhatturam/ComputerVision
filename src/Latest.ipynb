{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import cv2\n",
    "from incisorseg.dataset import Dataset,LeaveOneOutSplitter,appearance_model_eight_teeth,appearance_model_four_teeth,load_image,load_landmark,gaussian_pyramid_down,tooth_splitter,tooth_models\n",
    "from incisorseg.utils import *\n",
    "from active_shape_models.models import ModedPCAModel,GaussianModel,PointDistributionModel,ActiveShapeModel\n",
    "from active_shape_models.shape import Shape, ShapeList,LineGenerator\n",
    "import json\n",
    "data = Dataset('../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GreyModel:\n",
    "    \"\"\" A grey level point model based on\n",
    "    Cootes, Timothy F., and Christopher J. Taylor.\n",
    "     \"Active Shape Model Search using Local Grey-Level Models:\n",
    "     A Quantitative Evaluation.\" BMVC. Vol. 93. 1993.\n",
    "     and\n",
    "     An Active Shape Model based on\n",
    "        Cootes, Tim, E. R. Baldock, and J. Graham.\n",
    "        \"An introduction to active shape models.\"\n",
    "        Image processing and analysis (2000): 223-248.\n",
    "\n",
    "        Attributes:\n",
    "            _point_models: The list of underlying point grey models (GaussianModel or ModedPCAModel)\n",
    "\n",
    "        Authors: David Torrejon and Bharath Venkatesh\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, training_images, training_shape_list, patch_num_pixels_length, patch_num_pixels_width,\n",
    "                 search_num_pixels, use_gradient=False, use_laplacian=False, kernel_size=-1, normalize_patch=False, use_moded_pca_model=False, mpca_variance_captured=0.9,\n",
    "                 normal_point_neighborhood=2):\n",
    "        self._point_models = []\n",
    "        self._using_pca_model = use_moded_pca_model\n",
    "        self._search_num_pixels = search_num_pixels\n",
    "        self._patch_num_pixels_length = patch_num_pixels_length\n",
    "        self._patch_num_pixels_width = patch_num_pixels_width\n",
    "        self._use_gradient = use_gradient\n",
    "        self._use_laplacian = use_laplacian\n",
    "        self._kernel_size = kernel_size\n",
    "        self._normalize = normalize_patch\n",
    "        self._normal_neighborhood = normal_point_neighborhood\n",
    "        for i in range(training_shape_list[0].get_size()):\n",
    "            patch_data_list = []\n",
    "            for j in range(len(training_images)):\n",
    "                patch_coordinate_list = self._get_patch_pixel_indices(training_shape_list[j], i,\n",
    "                                                                      self._patch_num_pixels_length,\n",
    "                                                                      self._patch_num_pixels_width)\n",
    "                levels = self._get_patch_data(training_images[j], patch_coordinate_list).flatten()\n",
    "                patch_data_list.append(levels)\n",
    "            patch_data = np.array(patch_data_list)\n",
    "            if self._using_pca_model:\n",
    "                self._point_models.append(ModedPCAModel(patch_data, pca_variance_captured=mpca_variance_captured))\n",
    "            else:\n",
    "                self._point_models.append(GaussianModel(patch_data))\n",
    "\n",
    "    def _get_patch_pixel_indices(self, shape, point_index, number_of_pixels_length, number_of_pixels_width):\n",
    "        coordinate_list = []\n",
    "        point = shape.get_point(point_index)\n",
    "        tangent_slope_vector, normal_slope_vector = shape.get_slope_vectors_at_point(point_index,\n",
    "                                                                                     self._normal_neighborhood)\n",
    "        normal_coordinates_generator = LineGenerator(point, normal_slope_vector)\n",
    "        normal_coordinate_list = normal_coordinates_generator.generate_two_sided(number_of_pixels_length)\n",
    "        for coordinates in normal_coordinate_list:\n",
    "            tangent_coordinates_generator = LineGenerator(coordinates, tangent_slope_vector)\n",
    "            tangent_coordinate_list=tangent_coordinates_generator.generate_two_sided(number_of_pixels_width)\n",
    "            coordinate_list.append(tangent_coordinate_list)\n",
    "        return coordinate_list\n",
    "\n",
    "    def _get_patch_data(self, image, patch_coordinate_list, default_value=float(\"inf\"), break_on_error=True):\n",
    "        h, w = image.shape\n",
    "        patch_l = len(patch_coordinate_list)\n",
    "        patch_w = len(patch_coordinate_list[0])\n",
    "        data = np.zeros((patch_l, patch_w))\n",
    "        for i in range(patch_l):\n",
    "            for j in range(patch_w):\n",
    "                coordinates = patch_coordinate_list[i][j]\n",
    "                if 0 <= coordinates[1] < h and 0 < coordinates[0] < w:\n",
    "                    data[i, j] = image[coordinates[1], coordinates[0]]\n",
    "                elif break_on_error:\n",
    "                    raise ValueError(\"Index exceeds image dimensions\")\n",
    "                else:\n",
    "                    data[i, j] = default_value\n",
    "        if self._use_laplacian:\n",
    "            data = cv2.Laplacian(data, 6, ksize=np.abs(self._kernel_size))\n",
    "        elif self._use_gradient:\n",
    "            sobelx = cv2.Sobel(data,6,1,0,ksize=self._kernel_size)\n",
    "            sobely = cv2.Sobel(data,6,0,1,ksize=self._kernel_size)\n",
    "            data = np.sqrt(sobelx**2 + sobely**2)\n",
    "        if self._normalize:\n",
    "            data = cv2.normalize(data,data, norm_type=2)\n",
    "        return data\n",
    "\n",
    "    def get_size(self):\n",
    "        \"\"\"\n",
    "        Returns the number of grey point models - i.e the number of landmarks\n",
    "        :return: Number of point models\n",
    "        \"\"\"\n",
    "        return len(self._point_models)\n",
    "\n",
    "    def get_point_grey_model(self, point_index):\n",
    "        \"\"\"\n",
    "        :param point_index: The index of the landmark\n",
    "        :return: The modedPCAModel for the landmark\n",
    "        \"\"\"\n",
    "        return self._point_models[point_index]\n",
    "\n",
    "    def search(self, test_image, initial_shape):\n",
    "        \"\"\"\n",
    "        Searches for the best positions of the shape points in the test image\n",
    "        :param test_image: The test image\n",
    "        :param initial_shape: The initial shape\n",
    "        :return: The new shape, and the array of errors - empty if the shape hasnt moved\n",
    "        \"\"\"\n",
    "        point_list = []\n",
    "        error_list = []\n",
    "        for point_index in range(self.get_size()):\n",
    "            grey_model = self._point_models[point_index]\n",
    "            patch_coordinate_list = self._get_patch_pixel_indices(initial_shape, point_index,\n",
    "                                                                  self._search_num_pixels,\n",
    "                                                                  self._patch_num_pixels_width)\n",
    "            full_test_patch = self._get_patch_data(test_image, patch_coordinate_list)\n",
    "            min_index = -1\n",
    "            min_error = float(\"inf\")\n",
    "            all_errors = []\n",
    "            for i in range(2*self._search_num_pixels -(2*self._patch_num_pixels_length)):\n",
    "                select_range = range(i, i + 2*self._patch_num_pixels_length+1)\n",
    "                current_test_patch = full_test_patch[select_range,:]\n",
    "                error, _, _ = grey_model.fit(current_test_patch.flatten())\n",
    "                all_errors.append(error)\n",
    "                if error < min_error:\n",
    "                    min_index = i\n",
    "                    min_error = error\n",
    "            plot_line(all_errors)\n",
    "            print point_index,np.mean(all_errors),np.std(all_errors),min_index,self._search_num_pixels-self._patch_num_pixels_length,all_errors[self._search_num_pixels-self._patch_num_pixels_length],min_error\n",
    "            if min_index == -1:\n",
    "                point_list.append(initial_shape.get_point(point_index))\n",
    "            else:\n",
    "                point_list.append(patch_coordinate_list[min_index+self._patch_num_pixels_length][self._patch_num_pixels_width])\n",
    "            error_list.append(min_error)\n",
    "        return Shape(np.array(point_list)), np.array(error_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for split in LeaveOneOutSplitter(data,Dataset.ALL_TRAINING_IMAGES,Dataset.ALL_TEETH):\n",
    "    training_images,training_landmarks,training_segmentations = split.get_training_set()\n",
    "    test_image,test_landmark,test_segmentation = split.get_test_example()\n",
    "    transformed_test_image = test_image\n",
    "    transformed_training_images = training_images\n",
    "    #transformed_training_images = [cv2.Laplacian(image,ddepth=cv2.CV_32F) for image in scaled_training_images]\n",
    "    #transformed_test_image = cv2.Laplacian(scaled_test_image,ddepth=cv2.CV_32F)\n",
    "    transformed_training_images = [cv2.medianBlur(image,7) for image in transformed_training_images]\n",
    "    transformed_test_image = cv2.medianBlur(transformed_test_image,7)\n",
    "    #shape_model = PointDistributionModel(training_landmarks,use_transformation_matrix=True,project_to_tangent_space=True)\n",
    "    grey_model = GreyModel(transformed_training_images, training_landmarks,patch_num_pixels_length=3,patch_num_pixels_width=3,\n",
    "                           search_num_pixels=10, use_laplacian=False,use_gradient=False,\n",
    "                 normalize_patch=True, use_moded_pca_model=False, mpca_variance_captured=0.9,\n",
    "                 normal_point_neighborhood=2)\n",
    "    #active_shape_model = ActiveShapeModel(shape_model,grey_model)\n",
    "    new_shape,_= grey_model.search(transformed_test_image,test_landmark)\n",
    "    #newer_shape,_,_ = shape_model.fit(new_shape)\n",
    "    #newest_shape,_,_ = active_shape_model.fit(transformed_test_image,initial_shape=test_landmark)\n",
    "    plot_shapes([test_landmark,new_shape])\n",
    "    #plot_shapes([test_landmark,newer_shape])\n",
    "    #plot_shapes([test_landmark,newest_shape])\n",
    "    #print split.get_dice_error_on_test(new_shape),split.get_dice_error_on_test(newer_shape),split.get_dice_error_on_test(newest_shape)\n",
    "    #error_list.append(split.get_dice_error_on_test(newest_shape))\n",
    "    i = i+1\n",
    "    if i >= 1:\n",
    "        break\n",
    "print np.mean(np.array(error_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
