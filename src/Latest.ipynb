{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import cv2\n",
    "from incisorseg.dataset import Dataset,LeaveOneOutSplitter,appearance_model_eight_teeth,appearance_model_four_teeth,load_image,load_landmark,gaussian_pyramid_down,tooth_splitter,tooth_models\n",
    "from incisorseg.utils import *\n",
    "from active_shape_models.models import ModedPCAModel,GaussianModel,PointDistributionModel,ActiveShapeModel\n",
    "from active_shape_models.shape import Shape, ShapeList,LineGenerator\n",
    "import json\n",
    "data = Dataset('../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GreyModel:\n",
    "    \"\"\" A grey level point model based on\n",
    "    Cootes, Timothy F., and Christopher J. Taylor.\n",
    "     \"Active Shape Model Search using Local Grey-Level Models:\n",
    "     A Quantitative Evaluation.\" BMVC. Vol. 93. 1993.\n",
    "     and\n",
    "     An Active Shape Model based on\n",
    "        Cootes, Tim, E. R. Baldock, and J. Graham.\n",
    "        \"An introduction to active shape models.\"\n",
    "        Image processing and analysis (2000): 223-248.\n",
    "\n",
    "        Attributes:\n",
    "            _point_models: The list of underlying point grey models (GaussianModel or ModedPCAModel)\n",
    "\n",
    "        Authors: David Torrejon and Bharath Venkatesh\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, training_images, training_shape_list, patch_num_pixels_length, patch_num_pixels_width,\n",
    "                 search_num_pixels, use_gradient=False, use_template_match=False,use_laplacian=False, kernel_size=-1, normalize_patch=False, use_moded_pca_model=False, mpca_variance_captured=0.9,\n",
    "                 normal_point_neighborhood=2):\n",
    "        self._point_models = []\n",
    "        self._using_pca_model = use_moded_pca_model\n",
    "        self._use_template_match = use_template_match\n",
    "        self._search_num_pixels = search_num_pixels\n",
    "        self._patch_num_pixels_length = patch_num_pixels_length\n",
    "        self._patch_num_pixels_width = patch_num_pixels_width\n",
    "        self._use_gradient = use_gradient\n",
    "        self._use_laplacian = use_laplacian\n",
    "        self._kernel_size = kernel_size\n",
    "        self._normalize = normalize_patch\n",
    "        self._normal_neighborhood = normal_point_neighborhood\n",
    "        for i in range(training_shape_list[0].get_size()):\n",
    "            patch_data_list = []\n",
    "            for j in range(len(training_images)):\n",
    "                patch_coordinate_list = self._get_patch_pixel_indices(training_shape_list[j], i,\n",
    "                                                                      self._patch_num_pixels_length,\n",
    "                                                                      self._patch_num_pixels_width)\n",
    "                patch = self._get_patch_data(training_images[j], patch_coordinate_list)\n",
    "                levels = patch.flatten()\n",
    "                if not self._use_template_match:\n",
    "                    patch_data_list.append(levels)\n",
    "                else:\n",
    "                    patch_data_list.append(patch)\n",
    "            if not self._use_template_match:\n",
    "                patch_data = np.array(patch_data_list)\n",
    "                if self._using_pca_model:\n",
    "                    self._point_models.append(ModedPCAModel(patch_data, pca_variance_captured=mpca_variance_captured))\n",
    "                else:\n",
    "                    self._point_models.append(GaussianModel(patch_data))\n",
    "            else:\n",
    "                np.mean(np.array(patch_data_list),axis=0)\n",
    "                self._point_models.append(patch_data)\n",
    "\n",
    "    def _get_patch_pixel_indices(self, shape, point_index, number_of_pixels_length, number_of_pixels_width):\n",
    "        coordinate_list = []\n",
    "        point = shape.get_point(point_index)\n",
    "        tangent_slope_vector, normal_slope_vector = shape.get_slope_vectors_at_point(point_index,\n",
    "                                                                                     self._normal_neighborhood)\n",
    "        normal_coordinates_generator = LineGenerator(point, normal_slope_vector)\n",
    "        normal_coordinate_list = normal_coordinates_generator.generate_two_sided(number_of_pixels_length)\n",
    "        for coordinates in normal_coordinate_list:\n",
    "            tangent_coordinates_generator = LineGenerator(coordinates, tangent_slope_vector)\n",
    "            tangent_coordinate_list=tangent_coordinates_generator.generate_two_sided(number_of_pixels_width)\n",
    "            coordinate_list.append(tangent_coordinate_list)\n",
    "        return coordinate_list\n",
    "\n",
    "    def _get_patch_data(self, image, patch_coordinate_list, default_value=float(\"inf\"), break_on_error=True):\n",
    "        h, w = image.shape\n",
    "        patch_l = len(patch_coordinate_list)\n",
    "        patch_w = len(patch_coordinate_list[0])\n",
    "        data = np.zeros((patch_l, patch_w))\n",
    "        for i in range(patch_l):\n",
    "            for j in range(patch_w):\n",
    "                coordinates = patch_coordinate_list[i][j]\n",
    "                if 0 <= coordinates[1] < h and 0 < coordinates[0] < w:\n",
    "                    data[i, j] = image[coordinates[1], coordinates[0]]\n",
    "                elif break_on_error:\n",
    "                    raise ValueError(\"Index exceeds image dimensions\")\n",
    "                else:\n",
    "                    data[i, j] = default_value\n",
    "        if self._use_laplacian:\n",
    "            data = cv2.Laplacian(data, 6, ksize=np.abs(self._kernel_size))\n",
    "        elif self._use_gradient:\n",
    "            sobelx = cv2.Sobel(data,6,1,0,ksize=self._kernel_size)\n",
    "            sobely = cv2.Sobel(data,6,0,1,ksize=self._kernel_size)\n",
    "            data = np.sqrt(sobelx**2 + sobely**2)\n",
    "        if self._normalize:\n",
    "            data = cv2.normalize(data,data, norm_type=2)\n",
    "        return data\n",
    "\n",
    "    def get_size(self):\n",
    "        \"\"\"\n",
    "        Returns the number of grey point models - i.e the number of landmarks\n",
    "        :return: Number of point models\n",
    "        \"\"\"\n",
    "        return len(self._point_models)\n",
    "\n",
    "    def get_point_grey_model(self, point_index):\n",
    "        \"\"\"\n",
    "        :param point_index: The index of the landmark\n",
    "        :return: The modedPCAModel for the landmark\n",
    "        \"\"\"\n",
    "        return self._point_models[point_index]\n",
    "    \n",
    "    def _search_using_model(self,grey_model,full_test_patch):\n",
    "        all_errors = []\n",
    "        min_error = float(\"inf\")\n",
    "        min_index = -1\n",
    "        for i in range(2*self._search_num_pixels -(2*self._patch_num_pixels_length)):\n",
    "            select_range = range(i, i + 2*self._patch_num_pixels_length+1)\n",
    "            current_test_patch = full_test_patch[select_range,:]\n",
    "            error, _, _ = grey_model.fit(current_test_patch.flatten())\n",
    "            all_errors.append(error)\n",
    "            if error < min_error:\n",
    "                min_index = i\n",
    "                min_error = error\n",
    "        return min_index,min_error,all_errors\n",
    "    \n",
    "    def _search_using_template_match(self,template,test_image):\n",
    "        ret = cv2.matchTemplate(test_image, template, method=3)\n",
    "        hh,ww = test_image.shape\n",
    "        h, w = template.shape                                    \n",
    "        if ret.shape == test_image.shape:\n",
    "            mask = np.uint8(np.zeros(test_image.shape))\n",
    "            mask[:,self._patch_num_pixels_width] = np.ones(2*self._patch_num_pixels_length+1)\n",
    "            _, maxVal, _, max_loc = cv2.minMaxLoc(ret, mask=mask)\n",
    "            all_errors = np.squeeze(ret[:,self._patch_num_pixels_width])\n",
    "            all_errors = all_err[0:(hh - h + 1)].tolist()\n",
    "        else:\n",
    "            mask = np.ones(2*self._patch_num_pixels_length+1)\n",
    "            _, _, _, max_loc = cv2.minMaxLoc(np.multiply(ret,mask))\n",
    "            all_errors = np.squeeze(ret).tolist()\n",
    "        translation = max_loc + np.round([w / 2.0, h / 2.0])\n",
    "        return translation[1],maxVal,all_errors\n",
    "\n",
    "    def search(self, test_image, initial_shape):\n",
    "        \"\"\"\n",
    "        Searches for the best positions of the shape points in the test image\n",
    "        :param test_image: The test image\n",
    "        :param initial_shape: The initial shape\n",
    "        :return: The new shape, and the array of errors - empty if the shape hasnt moved\n",
    "        \"\"\"\n",
    "        point_list = []\n",
    "        error_list = []\n",
    "        for point_index in range(self.get_size()):\n",
    "            grey_model = self._point_models[point_index]\n",
    "            patch_coordinate_list = self._get_patch_pixel_indices(initial_shape, point_index,\n",
    "                                                                  self._search_num_pixels,\n",
    "                                                                  self._patch_num_pixels_width)\n",
    "            full_test_patch = self._get_patch_data(test_image, patch_coordinate_list)\n",
    "            if not self._use_template_match:\n",
    "                min_index,all_errors = self._search_using_model(grey_model,full_test_patch)\n",
    "            else:\n",
    "                min_index,min_error,all_errors = self._search_using_template_match(grey_model,full_test_patch)\n",
    "            plot_line(all_errors)\n",
    "            print point_index,np.mean(all_errors),np.std(all_errors),min_index,self._search_num_pixels-self._patch_num_pixels_length,all_errors[self._search_num_pixels-self._patch_num_pixels_length],min_error\n",
    "            if min_index == -1:\n",
    "                point_list.append(initial_shape.get_point(point_index))\n",
    "            else:\n",
    "                point_list.append(patch_coordinate_list[min_index+self._patch_num_pixels_length][self._patch_num_pixels_width])\n",
    "            error_list.append(min_error)\n",
    "        return Shape(np.array(point_list)), np.array(error_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-4c4e6cf0dde3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m                  normal_point_neighborhood=2)\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m#active_shape_model = ActiveShapeModel(shape_model,grey_model)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mnew_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mgrey_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformed_test_image\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_landmark\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;31m#newer_shape,_,_ = shape_model.fit(new_shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m#newest_shape,_,_ = active_shape_model.fit(transformed_test_image,initial_shape=test_landmark)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-833b1699d8fc>\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, test_image, initial_shape)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mfull_test_patch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_patch_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatch_coordinate_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_use_template_match\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m                 \u001b[0mmin_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mall_errors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_search_using_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrey_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfull_test_patch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m                 \u001b[0mmin_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_error\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mall_errors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_search_using_template_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrey_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfull_test_patch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for split in LeaveOneOutSplitter(data,Dataset.ALL_TRAINING_IMAGES,Dataset.ALL_TEETH):\n",
    "    training_images,training_landmarks,training_segmentations = split.get_training_set()\n",
    "    test_image,test_landmark,test_segmentation = split.get_test_example()\n",
    "    transformed_test_image = test_image\n",
    "    transformed_training_images = training_images\n",
    "    #transformed_training_images = [cv2.medianBlur(image,5) for image in transformed_training_images]\n",
    "    #transformed_test_image = cv2.medianBlur(transformed_test_image,5)\n",
    "    #shape_model = PointDistributionModel(training_landmarks,use_transformation_matrix=True,project_to_tangent_space=True)\n",
    "    grey_model = GreyModel(transformed_training_images, training_landmarks,patch_num_pixels_length=4,patch_num_pixels_width=5,\n",
    "                           search_num_pixels=16,use_template_match=False, use_laplacian=True,use_gradient=False,\n",
    "                 normalize_patch=True, use_moded_pca_model=False, mpca_variance_captured=0.9,\n",
    "                 normal_point_neighborhood=2)\n",
    "    #active_shape_model = ActiveShapeModel(shape_model,grey_model)\n",
    "    new_shape,_= grey_model.search(transformed_test_image,test_landmark)\n",
    "    #newer_shape,_,_ = shape_model.fit(new_shape)\n",
    "    #newest_shape,_,_ = active_shape_model.fit(transformed_test_image,initial_shape=test_landmark)\n",
    "    plot_shapes([test_landmark,new_shape])\n",
    "    #plot_shapes([test_landmark,newer_shape])\n",
    "    #plot_shapes([test_landmark,newest_shape])\n",
    "    #print split.get_dice_error_on_test(new_shape),split.get_dice_error_on_test(newer_shape),split.get_dice_error_on_test(newest_shape)\n",
    "    #error_list.append(split.get_dice_error_on_test(newest_shape))\n",
    "    i = i+1\n",
    "    if i >= 1:\n",
    "        break\n",
    "print np.mean(np.array(error_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
